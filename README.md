

# ğŸ“Š Performance PostgreSQL - E-Learning Platform

Ce projet est une Ã©tude de performance d'une plateforme e-learning utilisant **PostgreSQL** pour identifier les goulets d'Ã©tranglement, analyser les plans d'exÃ©cution et mettre en place une stratÃ©gie d'optimisation.

---

## ğŸ¯ Objectif GÃ©nÃ©ral

Concevoir, analyser et optimiser une base de donnÃ©es PostgreSQL utilisÃ©e par une plateforme e-learning afin de :

- Comprendre le fonctionnement interne du moteur PostgreSQL
- Analyser les plans d'exÃ©cution des requÃªtes
- Identifier les goulets d'Ã©tranglement
- Mettre en place une stratÃ©gie d'indexation pertinente
- Mesurer objectivement les gains de performance

---

# ğŸ“ Partie 1 â€” Mise en place de la plateforme

## 1.1 SchÃ©ma Relationnel

La base de donnÃ©es gÃ¨re les entitÃ©s suivantes :

### Tables Ã  crÃ©er

#### 1. **students**
Table contenant les informations des Ã©tudiants inscrits Ã  la plateforme.

**Colonnes** :
- `student_id` (PK) : Identifiant unique
- `username` : Nom d'utilisateur (unique)
- `email` : Adresse email (unique)
- `first_name` : PrÃ©nom
- `last_name` : Nom
- `enrollment_date` : Date d'inscription
- `status` : Ã‰tat du compte (active, inactive, suspended)

#### 2. **courses**
Table contenant les cours disponibles sur la plateforme.

**Colonnes** :
- `course_id` (PK) : Identifiant unique du cours
- `course_name` : Nom du cours
- `description` : Description dÃ©taillÃ©e
- `category` : CatÃ©gorie du cours
- `instructor_id` : Identifiant de l'instructeur
- `created_date` : Date de crÃ©ation
- `level` : Niveau de difficultÃ© (beginner, intermediate, advanced)

#### 3. **enrollments**
Table de liaison pour gÃ©rer les inscriptions des Ã©tudiants aux cours.

**Colonnes** :
- `enrollment_id` (PK) : Identifiant unique
- `student_id` (FK) : RÃ©fÃ©rence Ã  students
- `course_id` (FK) : RÃ©fÃ©rence Ã  courses
- `enrollment_date` : Date d'inscription au cours
- `completion_date` : Date de fin (NULL si non complÃ©tÃ©)
- `progress` : Progression en pourcentage
- `grade` : Note finale

#### 4. **access_logs**
Table des logs d'accÃ¨s pour suivre l'activitÃ© des utilisateurs.

**Colonnes** :
- `log_id` (PK) : Identifiant unique
- `student_id` (FK) : RÃ©fÃ©rence Ã  students
- `course_id` (FK) : RÃ©fÃ©rence Ã  courses
- `access_timestamp` : Horodatage de l'accÃ¨s
- `session_duration` : DurÃ©e de la session (en secondes)
- `ip_address` : Adresse IP
- `user_agent` : Agent utilisateur
- `action_type` : Type d'action (login, view, upload, download)

---

## 1.2 Choix des Types de DonnÃ©es

| Colonne | Type PostgreSQL | Justification |
|---------|-----------------|---------------|
| `student_id` / `course_id` / `enrollment_id` / `log_id` | `BIGSERIAL` | Identifiants auto-incrÃ©mentÃ©s, supportent grandes volumÃ©tries |
| `username` / `email` / `first_name` / `last_name` | `VARCHAR(255)` | Texte variable, limite raisonnable |
| `enrollment_date` / `created_date` / `completion_date` | `DATE` | Dates sans heure |
| `access_timestamp` | `TIMESTAMP WITH TIME ZONE` | Horodatage prÃ©cis et fuseau horaire |
| `progress` / `grade` | `NUMERIC(5, 2)` | Valeurs dÃ©cimales prÃ©cises |
| `session_duration` | `INTEGER` | Secondes (nombre entier) |
| `status` / `level` / `category` / `action_type` | `VARCHAR(50)` | Ã‰numÃ©rations textuelles |

---

## 1.3 MÃ©thode de GÃ©nÃ©ration des DonnÃ©es

Les donnÃ©es sont gÃ©nÃ©rÃ©es automatiquement avec les volumÃ©tries suivantes :

| Table | Volume | Justification |
|-------|--------|---------------|
| `students` | 200 000 | ReprÃ©sente une user base rÃ©aliste |
| `courses` | 1 000 | Nombre modÃ©rÃ© de cours |
| `enrollments` | 2 000 000 | ~10 inscriptions par Ã©tudiant en moyenne |
| `access_logs` | 5 000 000 | ~2-3 accÃ¨s par inscription (requÃªtes coÃ»teuses) |

**Approche** :
- Utilisation de boucles PL/pgSQL pour gÃ©nÃ©rer les donnÃ©es
- DonnÃ©es rÃ©alistes : dates cohÃ©rentes, ID valides, distributions alÃ©atoires
- Chargement par batch pour optimiser les performances d'insertion

---

## 1.4 VÃ©rifications EffectuÃ©es

### âœ… CohÃ©rence des donnÃ©es

- ClÃ©s Ã©trangÃ¨res : Tous les `student_id` et `course_id` dans `enrollments` et `access_logs` existent dans leurs tables respectives
- IntÃ©gritÃ© temporelle : `completion_date >= enrollment_date` dans enrollments
- Contraintes uniques : `username` et `email` uniques dans `students`

### âœ… Taille disque

Estimation avant gÃ©nÃ©ration :
```
students (200K rows)      : ~50 MB
courses (1K rows)         : ~2 MB
enrollments (2M rows)     : ~500 MB
access_logs (5M rows)     : ~1.5 GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total                     : ~2.1 GB
```

### âœ… Temps de chargement

- GÃ©nÃ©ration et insertion des donnÃ©es : < 10 minutes
- CrÃ©ation des index : < 5 minutes
- Total : ~15 minutes

---

## ğŸ¯ Objectif

Analyser et comparer les performances de deux bases de donnÃ©es modernes :
- **MongoDB** : Base de donnÃ©es NoSQL orientÃ©e documents
- **Supabase** : PostgreSQL managÃ© (SQL relationnel)

Ã€ travers diffÃ©rents types de requÃªtes et avec/sans index.

---

## ğŸ“ Structure du Projet

```
Performance_postgre/
â”œâ”€â”€ venv/
â”‚   â”œâ”€â”€ .env                    # Variables d'environnement (Ã  configurer)
â”‚   â”œâ”€â”€ test_connexion.py       # Script de test de connexion
â”‚   â”œâ”€â”€ TP2/
â”‚   â”‚   â”œâ”€â”€ TP2_API.py         # Pipeline de collecte et migration
â”‚   â”‚   â””â”€â”€ Test_perf.py       # Suite de benchmark
â”‚   â””â”€â”€ ...
â”œâ”€â”€ README.md                   # Ce fichier
â””â”€â”€ .git/                       # Historique Git
```

---

## ğŸš€ Installation

### 1. PrÃ©requis

- Python 3.10+
- pip (gestionnaire de paquets Python)
- Compte MongoDB Atlas
- Compte Supabase

### 2. Installation des dÃ©pendances

```bash
# Naviguer vers le dossier du projet
cd venv

# Installer les packages requis
pip install pymongo psycopg2-binary requests python-dotenv pandas
```

### 3. Configuration du fichier `.env`

CrÃ©er ou modifier le fichier `.env` dans le dossier `venv/` :

```env
# MongoDB Atlas
M_url=mongodb+srv://<username>:<password>@<cluster>.mongodb.net/ISS_DB

# API ISS
ISS_api_url=http://api.open-notify.org/iss-now.json

# Supabase/PostgreSQL
Supabase_url=postgresql://<user>:<password>@<host>:<port>/postgres
```

---

## ğŸ“ Fichiers Principaux

### `test_connexion.py`
**Objectif** : Tester les connexions Ã  tous les services

```bash
python test_connexion.py
```

**Tests effectuÃ©s** :
- âœ… Connexion Ã  MongoDB Atlas
- âœ… RÃ©cupÃ©ration des donnÃ©es ISS (API)
- âœ… Connexion Ã  Supabase

---

### `TP2_API.py`
**Objectif** : Pipeline complet de collecte et migration des donnÃ©es

```bash
python TP2_API.py
```

**Workflow** :

```
1. RÃ©cupÃ©ration des donnÃ©es ISS (API)
   â†“
2. Stockage dans MongoDB (200 itÃ©rations)
   â†“
3. Lecture depuis MongoDB
   â†“
4. Transformation en DataFrame (pandas)
   â†“
5. Ã‰criture dans Supabase
   â†“
6. Gestion des doublons (via mongo_id)
```

**Fonctions principales** :

| Fonction | Description |
|----------|-------------|
| `fetch_and_store_multiple()` | RÃ©cupÃ¨re les donnÃ©es ISS N fois avec dÃ©lai |
| `read_data_from_mongodb()` | Lit tous les documents MongoDB |
| `transform_to_dataframe()` | Convertit les donnÃ©es en DataFrame propre |
| `write_to_supabase()` | Ã‰crit dans Supabase sans doublons |
| `migrate_mongodb_to_supabase()` | Pipeline complet |

**DonnÃ©es collectÃ©es** :
- Latitude et Longitude de l'ISS
- Timestamp (Unix, converti en datetime)
- Identifiant MongoDB (mongo_id) pour traÃ§abilitÃ©

---

### `Test_perf.py`
**Objectif** : Benchmark et comparaison des performances

```bash
python Test_perf.py
```

**6 Tests effectuÃ©s** :

#### TEST 1: SELECT Simple
- RÃ©cupÃ¨re tous les documents/lignes
- Mesure le temps baseline

#### TEST 2: SELECT avec Filtre
- RequÃªte filtrÃ©e sur latitude > 0
- Comparaison des temps d'exÃ©cution

#### TEST 3: AgrÃ©gation
- COUNT et AVG(latitude)
- Compare les capacitÃ©s d'agrÃ©gation

#### TEST 4: Filtre Longitude (SANS INDEX)
- Baseline pour l'impact des index
- Filtre sur longitude > 30

#### TEST 5: Filtre Longitude (AVEC INDEX)
- CrÃ©ation automatique des index
- Mesure de l'amÃ©lioration apportÃ©e

#### TEST 6: Impact des INDEX
- Comparaison directe avant/aprÃ¨s index
- Calcul du gain de performance

---

## ğŸ“Š RÃ©sultats Attendus

### Format de Sortie

```
======================================================================
STATISTIQUES DES BASES
======================================================================

ğŸ“¦ MONGODB:
  Collection: ISS_loc
  Nombre de documents: 200
  Taille moyenne d'un doc: 342 bytes
  Taille totale: 0.12 MB

ğŸ“¦ SUPABASE:
  Table: iss_data
  Nombre de lignes: 200
  Taille de la table: 48.00 kB

======================================================================
RÃ‰SUMÃ‰ COMPARATIF
======================================================================

              Test        MongoDB (ms)  Supabase (ms)  Ratio (M/S)   Gagnant
    SELECT Simple              5.32           2.15         2.47x    SUPABASE
 SELECT avec Filtre            3.21           1.89         1.70x    SUPABASE
      AgrÃ©gation              12.45          4.32          2.88x    SUPABASE
Filtre Longitude (SANS INDEX)  15.23         28.45         0.54x    MONGODB
Filtre Longitude (AVEC INDEX)   2.11          1.45         1.46x    SUPABASE
```

---

## ğŸ” FonctionnalitÃ©s ClÃ©s

### MongoDB
- âœ… CrÃ©ation automatique de collections
- âœ… Gestion des index
- âœ… AgrÃ©gations ($group, $match)
- âœ… Stats de collections (size, avgObjSize)

### Supabase
- âœ… Gestion des tables avec UNIQUE constraints
- âœ… EXPLAIN ANALYZE pour l'optimisation
- âœ… Index automatiques
- âœ… Stats de tables (pg_size_pretty)

### Gestion des Doublons
- âœ… VÃ©rification via `mongo_id`
- âœ… Pas de rÃ©Ã©criture des entrÃ©es existantes
- âœ… Compteur de lignes skippÃ©es

---

## ğŸ› ï¸ API et Fonctions

### Connexions

```python
# MongoDB
mongo_client = connect_mongodb()

# Supabase
supabase_conn = connect_supabase()
```

### RequÃªtes avec Mesure de Performance

```python
# MongoDB
result = query_mongodb_with_explain(client, {"field": {"$gt": value}})

# Supabase
result = query_supabase_with_explain(connection, "SELECT * FROM table WHERE field > 5")
```

### Index

```python
# CrÃ©er
create_mongodb_index(client, "iss_position.longitude")
create_supabase_index(connection, "longitude", "idx_longitude")

# Lister
list_mongodb_indexes(client)
list_supabase_indexes(connection)

# Supprimer
drop_mongodb_index(client, "index_name")
drop_supabase_index(connection, "index_name")
```

### Migration

```python
# Pipeline complet
migrate_mongodb_to_supabase()

# Ou Ã©tape par Ã©tape
documents = read_data_from_mongodb()
df = transform_to_dataframe(documents)
write_to_supabase(df)
```

---

## ğŸ’¡ InterprÃ©tation des RÃ©sultats

### Quand MongoDB est plus rapide ?
- âœ… Queries sans index sur trÃ¨s grandes collections
- âœ… Documents profondÃ©ment imbriquÃ©s
- âœ… AgrÃ©gations complexes avec multiples stages

### Quand Supabase/PostgreSQL est plus rapide ?
- âœ… Queries filtrÃ©es (avec index)
- âœ… JOINs de tables
- âœ… Transactions ACID
- âœ… RequÃªtes sur donnÃ©es normalisÃ©es

---

## ğŸ“ˆ Points d'AmÃ©lioration Possibles

- [ ] Tester avec des datasets plus volumineux (millions de documents)
- [ ] Ajouter des tests de JOINs pour Supabase
- [ ] ImplÃ©menter des stratÃ©gies de sharding MongoDB
- [ ] Analyser la consommation mÃ©moire
- [ ] Tests de scalabilitÃ© horizontale
- [ ] Benchmark des Ã©critures (INSERT) vs lectures (SELECT)

---

## ğŸ› Troubleshooting

### Erreur: "Authentication failed" MongoDB
- VÃ©rifier les identifiants dans `.env`
- VÃ©rifier que l'IP est whitelistÃ©e dans MongoDB Atlas
- S'assurer que le mot de passe ne contient pas de caractÃ¨res spÃ©ciaux non-encodÃ©s

### Erreur: "Connection refused" Supabase
- VÃ©rifier la structure de l'URL PostgreSQL
- S'assurer que le port (gÃ©nÃ©ralement 6543 ou 5432) est accessible
- VÃ©rifier les permissions de l'utilisateur PostgreSQL

### Erreur: "No module named 'psycopg2'"
```bash
pip install psycopg2-binary
```

### Erreur: "No module named 'pymongo'"
```bash
pip install pymongo
```

---

## ğŸ“š Ressources

- [MongoDB Documentation](https://docs.mongodb.com/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [Supabase Documentation](https://supabase.com/docs/)
- [Open Notify ISS API](http://api.open-notify.org/)

---

## ğŸ‘¤ Auteur

- **Ã‰tudiant** : Sobmathias
- **Formation** : Master 1 - Performance des Bases de DonnÃ©es
- **UniversitÃ©** : [Ã€ complÃ©ter]
- **Date** : Janvier 2026

---

## ğŸ“„ License

Ce projet est fourni Ã  titre Ã©ducatif.

---

## ğŸ“ Conclusion

Cette Ã©tude dÃ©montre que :

1. **PostgreSQL (Supabase)** excelle pour les requÃªtes filtrÃ©es avec index et les donnÃ©es structurÃ©es
2. **MongoDB** offre plus de flexibilitÃ© pour les documents complexes et imbriquÃ©s
3. **Les index sont cruciaux** pour les deux bases - L'impact peut Ãªtre de 5-10x
4. **Le choix dÃ©pend** du use case : SQL pour donnÃ©es relationnelles, NoSQL pour donnÃ©es semi-structurÃ©es

---

**DerniÃ¨re mise Ã  jour** : 20 Janvier 2026
