Phase 1 — Mise en place de la plateforme
Concevoir le schéma relationnel

Créer les tables :

students

courses

enrollments

access_logs

Choisir et justifier les types de données

Générer automatiquement les volumes .

Vérifier :

la cohérence des données

la taille disque

le temps de chargement

 

Phase 2 — Diagnostic des performances
Écrire plusieurs requêtes métier réalistes :

filtres simples

jointures

tris + LIMIT

Analyser chaque requête avec :

EXPLAIN

EXPLAIN ANALYZE

EXPLAIN (ANALYZE, BUFFERS)

Identifier :

types de scan (Seq / Index / Bitmap)

opérations de tri

types de jointures

nœuds dominants du plan

accès mémoire vs disque

Phase 3 — Optimisation et validation
Proposer une stratégie d’indexation

Implémenter les index

Comparer :

plans d’exécution avant / après

temps d’exécution

buffers

Identifier :

les requêtes améliorées

celles qui ne le sont pas

et expliquer pourquoi

Identifier au moins une requête mal conçue et proposer une correction

Livrables attendus
Chaque groupe doit rendre :

 Un rapport PDF contenant :

Schéma de la base

Choix des types

Méthode de génération des données

Requêtes analysées

Plans d’exécution avant / après

Analyse et conclusions

Un script SQL contenant :

Création des tables

Génération des données

Index

Requêtes utilisées

////

Objectif général
Concevoir, analyser et optimiser une base de données PostgreSQL utilisée par une plateforme e-learning afin de :

comprendre le fonctionnement interne du moteur PostgreSQL

analyser les plans d’exécution des requêtes

identifier les goulets d’étranglement

mettre en place une stratégie d’indexation pertinente

mesurer objectivement les gains de performance

 

Contexte métier
Vous travaillez pour une plateforme e-learning qui gère :

des étudiants

des cours

des inscriptions

des logs de connexions

La plateforme subit :

des lenteurs sur certaines pages

des requêtes de reporting très coûteuses

une croissance rapide du volume de données

Vous êtes chargé de diagnostiquer et corriger les problèmes de performance.

 

Architecture attendue
SGBD : PostgreSQL

Environnement : local ou Docker

Outil d’analyse : EXPLAIN / EXPLAIN ANALYZE

Client SQL : DBeaver / pgAdmin / psql

Modèle de données attendu :
students

courses

enrollments

access_logs

Volumétrie cible
Les données doivent être générées automatiquement :

Table	Volume
students	200 000
courses	1 000
enrollments	2 000 000
access_logs	5 000 000
Fonctionnement attendu
La base doit permettre :

des requêtes analytiques

des jointures massives

des tris

des filtres sur dates, catégories, étudiants

